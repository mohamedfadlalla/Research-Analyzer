{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from prompts import system_prompt_1, system_prompt_2\n",
    "\n",
    "import re\n",
    "import os \n",
    "from IPython.display import Markdown\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "# setup google gemini api keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_AI_STUDIO2')\n",
    "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "else:\n",
    "    raise OSError(\"Unsupported operating system\")\n",
    "\n",
    "\n",
    "pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=GOOGLE_API_KEY, temperature=0.4, convert_system_message_to_human=True)\n",
    "flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY, temperature=0.3, convert_system_message_to_human=True)\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-8b-8192\",\n",
    "    # model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjdblManpnnM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PDF Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "bYq4tu_roBQg"
   },
   "outputs": [],
   "source": [
    "#@title Depandances\n",
    "%%capture\n",
    "!pip3 install -U scidownl\n",
    "# Langchain and groq\n",
    "!pip install langchain\n",
    "!pip install langchain_groq\n",
    "\n",
    "#installing marker\n",
    "!pip install marker-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "BdNn168OoOwq",
    "outputId": "db1726c3-2b6e-4636-8101-c7550876da47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1cf9622b-a058-4ff4-9ade-346c2e4185f9\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1cf9622b-a058-4ff4-9ade-346c2e4185f9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdownload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mupload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid choice. Please enter 1 or 2.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36mupload_paper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Uploaded file is not a PDF file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scidownl import scihub_download\n",
    "import pandas as pd\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "def download_paper():\n",
    "    paper = input(\"Please enter the DOI of the paper here: \")\n",
    "    paper_type = \"doi\"\n",
    "    out = \"./paper.pdf\"\n",
    "    # Uncomment and configure the proxies if needed\n",
    "    # proxies = {\n",
    "    #     'http': 'socks5://127.0.0.1:7890'\n",
    "    # }\n",
    "    scihub_download(paper, paper_type=paper_type, out=out)#, proxies=proxies)\n",
    "\n",
    "def upload_paper():\n",
    "    uploaded = files.upload()\n",
    "    if not list(uploaded.keys())[0].endswith('.pdf'):\n",
    "        raise ValueError('Uploaded file is not a PDF file.')\n",
    "    os.rename(list(uploaded.keys())[0], 'paper.pdf')\n",
    "    print(\"Paper uploaded successfully as 'paper.pdf'\")\n",
    "\n",
    "def main():\n",
    "    choice = input(\"Choose an option (1 for DOI download, 2 for PDF upload): \")\n",
    "    if choice == '1':\n",
    "        download_paper()\n",
    "    elif choice == '2':\n",
    "        upload_paper()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u871l3MWPQ7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7w_hmCOpvnd",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Markdown Extraction with Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlzWKPpHUHNL"
   },
   "outputs": [],
   "source": [
    "#@title extracting markdown\n",
    "!marker_single /content/paper.pdf /content/output/ --batch_multiplier 2 --max_pages 20 --langs English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RogGmG7cp8-e"
   },
   "source": [
    "# Workflow extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "file_path = 'Examples/systematic_review/systematic_review.md'\n",
    "\n",
    "\n",
    "\n",
    "functions.get_workflow(file_path,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import summary\n",
    "import functions \n",
    "\n",
    "\n",
    "method = open()\n",
    "def main(method_text):\n",
    "    debug_mode = False  # Set debug_mode to False by default, can be adjusted as needed\n",
    "\n",
    "    # Placeholder for user input, replace with actual method section text input\n",
    "    method_text = \"\"\"Enter your method section text here.\"\"\"\n",
    "\n",
    "    if method_text:\n",
    "        # Create nodes and edges\n",
    "        method = toMarkdown(method_text)\n",
    "        nande = create_nodes_and_edges(method)\n",
    "\n",
    "        # Generate Graphviz code\n",
    "        llm_response = generate_graphviz_code(nande)\n",
    "\n",
    "        # Extract and execute the code\n",
    "        code = extract_code(llm_response)\n",
    "        \n",
    "        # Display debug information if debug mode is on\n",
    "        if debug_mode:\n",
    "            print(\"Debug Information\")\n",
    "            print(\"Nodes and Edges Content:\")\n",
    "            print(nande)\n",
    "            print(\"LLM Response Content:\")\n",
    "            print(llm_response)\n",
    "\n",
    "        # Execute the code\n",
    "        exec(code)\n",
    "        \n",
    "        # Look for the graph.png file\n",
    "        if os.path.exists(\"graph.png\"):\n",
    "            print(\"Generated graph.png file found.\")\n",
    "        else:\n",
    "            print(\"Unable to find the generated graph.png file.\")\n",
    "    else:\n",
    "        print(\"Please enter the method section text.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Comperhencive sammary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    # model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    # model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    # model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-8b-8192\",\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "##  Background and Objectives   \n",
       "The COVID-19 pandemic, caused by the SARS-CoV-2 virus, has become a global health crisis. The study aims to investigate the potential of repurposing FDA-approved drugs against SARS-CoV-2 virus using molecular docking and pharmacophore modeling.\n",
       "##  Methods                     \n",
       "**Methodology Summary:**\n",
       "\n",
       "* Design: Systematic search of scientific studies on Google Scholar\n",
       "* Sample: All studies published by the end of 2020/12/30\n",
       "* Tools/Techniques: \n",
       "  - Keywords: (COVID19 OR SARS-CoV-2) AND (Drug repurposing OR Drug repositioning OR Drug re-profling OR Drug rediscovery) AND (Docking AND Molecular dynamic)\n",
       "  - Database: Google Scholar\n",
       "##  Main Findings               \n",
       "* 1,444 studies on repurposing drugs for COVID-19 were collected from Google Scholar by the end of 2020/12/30.\n",
       "##  Analysis and Interpretation \n",
       "The authors used a systematic search strategy in Google Scholar to collect studies on drug repurposing for COVID-19, using a combination of keywords. The search was limited to studies published by the end of 2020/12/30.\n",
       "\n",
       "The authors did not mention any specific statistical methods used in the analysis. However, the results of the search strategy are likely to be presented in the form of a list of studies, which may be analyzed using descriptive statistics (e.g., frequency, percentage) to summarize the findings.\n",
       "\n",
       "The implications of the results are not explicitly stated, but the authors likely aim to provide an overview of the existing literature on drug repurposing for COVID-19, which can inform future research and clinical decisions.\n",
       "##  Contributions and Novelty   \n",
       "The paper contributes to the field of COVID-19 research by providing a comprehensive search strategy for identifying studies on repurposing drugs for COVID-19. The novel approach proposed is the use of a combination of keywords in the Google Scholar database to efficiently collect relevant studies.\n",
       "##  Limitations                 \n",
       "The study may be limited by the reliance on Google Scholar, which may not be comprehensive in capturing all relevant studies, particularly those published in non-English languages or in non-indexed journals. Additionally, the search strategy may be biased towards studies that used docking and molecular dynamics, potentially overlooking other repurposing methods.\n",
       "##  Conclusions and Recommendations \n",
       "The researchers conclude that antiviral drugs, particularly those targeting the main protease, show promise in the fight against COVID-19. Tetracyclines and antivirals, originally protease inhibitors, are recommended for further investigation. The models developed in this study can be used for virtual screening to aid in finding effective therapeutic agents against COVID-19.\n",
       "##  Key References and Citations \n",
       "Number of citaiton: 108"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Manuscript to pandas\n",
    "import summary\n",
    "import importlib\n",
    "importlib.reload(summary)\n",
    "\n",
    "file_path = 'Examples/systematic_review/systematic_review.md'\n",
    "results = summary.summarize(file_path, llm)\n",
    "Markdown(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.16.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\utils.py\", line 695, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2164\\2730648209.py\", line 53, in on_submit\n",
      "    results, summary_path = update_summary(file)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2164\\2730648209.py\", line 27, in update_summary\n",
      "    rawdata = file.read()\n",
      "              ^^^^^^^^^\n",
      "AttributeError: 'NamedString' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import summary\n",
    "import importlib\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "importlib.reload(summary)\n",
    "\n",
    "def summarize_file(file):\n",
    "    # Save the uploaded file\n",
    "    file_path = os.path.join(\"uploaded_files\", file.name)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file.read())\n",
    "    \n",
    "    # Summarize the file\n",
    "    results = summary.summarize(file_path, llm)\n",
    "    \n",
    "    # Write results to summary.md\n",
    "    summary_path = \"summary.md\"\n",
    "    with open(summary_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(results)\n",
    "    \n",
    "    return results, summary_path\n",
    "\n",
    "def update_summary(file):\n",
    "    # Detect file encoding\n",
    "    rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "    \n",
    "    # Save the uploaded file with the correct encoding\n",
    "    file_path = os.path.join(\"uploaded_files\", file.name)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(rawdata)\n",
    "    \n",
    "    # Summarize the file\n",
    "    results, summary_path = summarize_file(file_path)\n",
    "    return results, summary_path\n",
    "\n",
    "# Ensure the uploaded_files directory exists\n",
    "os.makedirs(\"uploaded_files\", exist_ok=True)\n",
    "\n",
    "# Gradio app\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Upload a file to summarize\")\n",
    "\n",
    "    file_input = gr.File(label=\"Upload your file\")\n",
    "    submit_button = gr.Button(\"Summarize\")\n",
    "    markdown_output = gr.Markdown(label=\"Summary\")\n",
    "    download_link = gr.File(label=\"Download Summary\", interactive=False)\n",
    "    \n",
    "    def on_submit(file):\n",
    "        results, summary_path = update_summary(file)\n",
    "        return results, summary_path\n",
    "\n",
    "    submit_button.click(on_submit, inputs=file_input, outputs=[markdown_output, download_link])\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "IlckXLp5p-7c"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
