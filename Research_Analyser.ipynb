{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# preprations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from prompts import system_prompt_1, system_prompt_2\n",
    "\n",
    "import re\n",
    "import os \n",
    "from IPython.display import Markdown\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "# setup google gemini api keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_AI_STUDIO2')\n",
    "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "else:\n",
    "    raise OSError(\"Unsupported operating system\")\n",
    "\n",
    "\n",
    "pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=GOOGLE_API_KEY, temperature=0.4, convert_system_message_to_human=True)\n",
    "flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY, temperature=0.3, convert_system_message_to_human=True)\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-8b-8192\",\n",
    "    # model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjdblManpnnM"
   },
   "source": [
    "# PDF Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "bYq4tu_roBQg"
   },
   "outputs": [],
   "source": [
    "#@title Depandances\n",
    "%%capture\n",
    "!pip3 install -U scidownl\n",
    "# Langchain and groq\n",
    "!pip install langchain\n",
    "!pip install langchain_groq\n",
    "\n",
    "#installing marker\n",
    "!pip install marker-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "BdNn168OoOwq",
    "outputId": "db1726c3-2b6e-4636-8101-c7550876da47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1cf9622b-a058-4ff4-9ade-346c2e4185f9\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1cf9622b-a058-4ff4-9ade-346c2e4185f9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdownload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mupload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid choice. Please enter 1 or 2.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fe3794aac9db>\u001b[0m in \u001b[0;36mupload_paper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Uploaded file is not a PDF file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scidownl import scihub_download\n",
    "import pandas as pd\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "def download_paper():\n",
    "    paper = input(\"Please enter the DOI of the paper here: \")\n",
    "    paper_type = \"doi\"\n",
    "    scihub_download(paper, paper_type=paper_type, out=out)#, proxies=proxies)\n",
    "\n",
    "def upload_paper():\n",
    "    uploaded = files.upload()\n",
    "    if not list(uploaded.keys())[0].endswith('.pdf'):\n",
    "        raise ValueError('Uploaded file is not a PDF file.')\n",
    "    os.rename(list(uploaded.keys())[0], 'paper.pdf')\n",
    "    print(\"Paper uploaded successfully as 'paper.pdf'\")\n",
    "\n",
    "def main():\n",
    "    choice = input(\"Choose an option (1 for DOI download, 2 for PDF upload): \")\n",
    "    if choice == '1':\n",
    "        download_paper()\n",
    "    elif choice == '2':\n",
    "        upload_paper()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u871l3MWPQ7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7w_hmCOpvnd"
   },
   "source": [
    "# Markdown Extraction with Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlzWKPpHUHNL"
   },
   "outputs": [],
   "source": [
    "#@title extracting markdown\n",
    "!marker_single /content/paper.pdf /content/output/ --batch_multiplier 2 --max_pages 20 --langs English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RogGmG7cp8-e"
   },
   "source": [
    "# Workflow extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "file_path = 'Examples/systematic_review/systematic_review.md'\n",
    "\n",
    "\n",
    "\n",
    "functions.get_workflow(file_path,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import summary\n",
    "import functions \n",
    "\n",
    "\n",
    "method = open()\n",
    "def main(method_text):\n",
    "    debug_mode = False  # Set debug_mode to False by default, can be adjusted as needed\n",
    "\n",
    "    # Placeholder for user input, replace with actual method section text input\n",
    "    method_text = \"\"\"Enter your method section text here.\"\"\"\n",
    "\n",
    "    if method_text:\n",
    "        # Create nodes and edges\n",
    "        method = toMarkdown(method_text)\n",
    "        nande = create_nodes_and_edges(method)\n",
    "\n",
    "        # Generate Graphviz code\n",
    "        llm_response = generate_graphviz_code(nande)\n",
    "\n",
    "        # Extract and execute the code\n",
    "        code = extract_code(llm_response)\n",
    "        \n",
    "        # Display debug information if debug mode is on\n",
    "        if debug_mode:\n",
    "            print(\"Debug Information\")\n",
    "            print(\"Nodes and Edges Content:\")\n",
    "            print(nande)\n",
    "            print(\"LLM Response Content:\")\n",
    "            print(llm_response)\n",
    "\n",
    "        # Execute the code\n",
    "        exec(code)\n",
    "        \n",
    "        # Look for the graph.png file\n",
    "        if os.path.exists(\"graph.png\"):\n",
    "            print(\"Generated graph.png file found.\")\n",
    "        else:\n",
    "            print(\"Unable to find the generated graph.png file.\")\n",
    "    else:\n",
    "        print(\"Please enter the method section text.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comperhencive sammary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    # model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    # model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    # model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-8b-8192\",\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "##  Background and Objectives   \n",
       "The COVID-19 pandemic, caused by the SARS-CoV-2 virus, has become a global health crisis. The study aims to investigate the potential of repurposing FDA-approved drugs against SARS-CoV-2 virus using molecular docking and pharmacophore modeling.\n",
       "##  Methods                     \n",
       "**Methodology Summary:**\n",
       "\n",
       "* Design: Systematic search of scientific studies on Google Scholar\n",
       "* Sample: All studies published by the end of 2020/12/30\n",
       "* Tools/Techniques: \n",
       "  - Keywords: (COVID19 OR SARS-CoV-2) AND (Drug repurposing OR Drug repositioning OR Drug re-profling OR Drug rediscovery) AND (Docking AND Molecular dynamic)\n",
       "  - Database: Google Scholar\n",
       "##  Main Findings               \n",
       "* 1,444 studies on repurposing drugs for COVID-19 were collected from Google Scholar by the end of 2020/12/30.\n",
       "##  Analysis and Interpretation \n",
       "The authors used a systematic search strategy in Google Scholar to collect studies on drug repurposing for COVID-19, using a combination of keywords. The search was limited to studies published by the end of 2020/12/30.\n",
       "\n",
       "The authors did not mention any specific statistical methods used in the analysis. However, the results of the search strategy are likely to be presented in the form of a list of studies, which may be analyzed using descriptive statistics (e.g., frequency, percentage) to summarize the findings.\n",
       "\n",
       "The implications of the results are not explicitly stated, but the authors likely aim to provide an overview of the existing literature on drug repurposing for COVID-19, which can inform future research and clinical decisions.\n",
       "##  Contributions and Novelty   \n",
       "The paper contributes to the field of COVID-19 research by providing a comprehensive search strategy for identifying studies on repurposing drugs for COVID-19. The novel approach proposed is the use of a combination of keywords in the Google Scholar database to efficiently collect relevant studies.\n",
       "##  Limitations                 \n",
       "The study may be limited by the reliance on Google Scholar, which may not be comprehensive in capturing all relevant studies, particularly those published in non-English languages or in non-indexed journals. Additionally, the search strategy may be biased towards studies that used docking and molecular dynamics, potentially overlooking other repurposing methods.\n",
       "##  Conclusions and Recommendations \n",
       "The researchers conclude that antiviral drugs, particularly those targeting the main protease, show promise in the fight against COVID-19. Tetracyclines and antivirals, originally protease inhibitors, are recommended for further investigation. The models developed in this study can be used for virtual screening to aid in finding effective therapeutic agents against COVID-19.\n",
       "##  Key References and Citations \n",
       "Number of citaiton: 108"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Manuscript to pandas\n",
    "import summary\n",
    "import importlib\n",
    "importlib.reload(summary)\n",
    "\n",
    "file_path = 'Examples/systematic_review/systematic_review.md'\n",
    "results = summary.summarize(file_path, llm)\n",
    "Markdown(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.16.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\miniconda3\\Lib\\site-packages\\gradio\\utils.py\", line 695, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2164\\2730648209.py\", line 53, in on_submit\n",
      "    results, summary_path = update_summary(file)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2164\\2730648209.py\", line 27, in update_summary\n",
      "    rawdata = file.read()\n",
      "              ^^^^^^^^^\n",
      "AttributeError: 'NamedString' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import summary\n",
    "import importlib\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "importlib.reload(summary)\n",
    "\n",
    "def summarize_file(file):\n",
    "    # Save the uploaded file\n",
    "    file_path = os.path.join(\"uploaded_files\", file.name)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file.read())\n",
    "    \n",
    "    # Summarize the file\n",
    "    results = summary.summarize(file_path, llm)\n",
    "    \n",
    "    # Write results to summary.md\n",
    "    summary_path = \"summary.md\"\n",
    "    with open(summary_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(results)\n",
    "    \n",
    "    return results, summary_path\n",
    "\n",
    "def update_summary(file):\n",
    "    # Detect file encoding\n",
    "    rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "    \n",
    "    # Save the uploaded file with the correct encoding\n",
    "    file_path = os.path.join(\"uploaded_files\", file.name)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(rawdata)\n",
    "    \n",
    "    # Summarize the file\n",
    "    results, summary_path = summarize_file(file_path)\n",
    "    return results, summary_path\n",
    "\n",
    "# Ensure the uploaded_files directory exists\n",
    "os.makedirs(\"uploaded_files\", exist_ok=True)\n",
    "\n",
    "# Gradio app\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Upload a file to summarize\")\n",
    "\n",
    "    file_input = gr.File(label=\"Upload your file\")\n",
    "    submit_button = gr.Button(\"Summarize\")\n",
    "    markdown_output = gr.Markdown(label=\"Summary\")\n",
    "    download_link = gr.File(label=\"Download Summary\", interactive=False)\n",
    "    \n",
    "    def on_submit(file):\n",
    "        results, summary_path = update_summary(file)\n",
    "        return results, summary_path\n",
    "\n",
    "    submit_button.click(on_submit, inputs=file_input, outputs=[markdown_output, download_link])\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critizim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Covid19 Approved Drug Repurposing: Pocket Similarity Approach Abstract:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Manuscript to pandas\n",
    "import summary\n",
    "import importlib\n",
    "import util\n",
    "importlib.reload(summary)\n",
    "\n",
    "file_path = 'Examples/pocket-similarity-approach/pocket-similarity-approach.md'\n",
    "outline = util.print_outline(file_path)\n",
    "title_method = summary.get_target_outline('method', outline, llm)\n",
    "title_abstract = summary.get_target_outline('abstract', outline, llm)\n",
    "Markdown(title_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = util.extract_section(file_path, title_abstract)\n",
    "method = util.extract_section(file_path, title_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Method: Similarity Calculation:\n",
       "\n",
       "Drug-protein complex preparation: All of the approved drugs were obtained from drugbank.ca, then the HET code of these drugs was obtained from http://ligand-expo.rcsb.org/. The list of HET codes was used to search on RCSB pdb, excluding the compound that appeared on more than 100 per structure because most of them are either small or not specific. A total of 4400 structures were retrieved from the RCSB database. After which all the pdbs were fed to a python script to clean the pdbs and leave only the drug and the chain that it binds to, the python script was designed to get all drugs even if they are in a single pdb structure and separate them in different pdbs. After which this list of pdb files was fed to Fpocket[11] to acquire the pockets of all the pdbs. Another python script which calculates pockets Center of mass. Also, the center of masses of each drug was calculated. After that, the distance between the Center of mass of the pocket and Center of mass of the drug was calculated to output a list of distances between the drug and all of the pockets of the protein.\n",
       "\n",
       "Then the smallest distance was chosen and the pocket that corresponds to this distance was output as a pdb file, doing this to all the drugs to obtain a list of all of the pockets of the drugs.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-70b-8192\",\n",
    "    # model_name=\"llama-3.1-70b-versatile\",\n",
    "    # model_name=\"mixtral-8x7b-32768\",\n",
    "    # model_name=\"llama3-8b-8192\",\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    # model_name=\"gemma2-9b-it\",\n",
    "    \n",
    "    groq_api_key=GROQ_API_KEY \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "##  **Clarity and Reproducibility**\n",
       "**Overall Evaluation**: The method section provides a clear description of the procedures used to identify potential inhibitors for SARS CoV 2 proteins. However, there are some areas that require clarification and improvement for better reproducibility.\n",
       "\n",
       "**Detailed Findings**:\n",
       "\n",
       "- **Procedure Descriptions**:\n",
       "\t+ The method section is well-structured, and the procedures are described in a logical order.\n",
       "\t+ However, some steps are not clearly explained, such as the use of Fpocket and the calculation of pocket center of mass.\n",
       "\t+ The use of Python scripts is mentioned, but the scripts themselves are not provided, which may make it difficult for others to reproduce the results.\n",
       "\t+ The method section could benefit from more detailed explanations of the algorithms and software used, such as PocketMatch and Fpocket.\n",
       "- **Materials and Equipment**:\n",
       "\t+ The study uses a variety of software and databases, including DrugBank, RCSB PDB, and Fpocket.\n",
       "\t+ However, the specific versions of these software and databases used are not mentioned, which may affect reproducibility.\n",
       "\t+ The study also uses Python scripts, but the specific versions of Python and any necessary libraries are not mentioned.\n",
       "- **Step-by-Step Protocols**:\n",
       "\t+ The method section provides a clear overview of the procedures, but some steps are not clearly explained.\n",
       "\t+ For example, the process of cleaning the PDB files and separating the drugs into different PDB structures is not clearly described.\n",
       "\t+ The method section could benefit from more detailed step-by-step protocols to ensure that others can reproduce the results.\n",
       "- **Ambiguities Identified**:\n",
       "\t+ The study uses a variety of software and databases, but the specific versions used are not mentioned.\n",
       "\t+ The study also uses Python scripts, but the specific versions of Python and any necessary libraries are not mentioned.\n",
       "\t+ The method section could benefit from more detailed explanations of the algorithms and software used to ensure reproducibility.\n",
       "\n",
       "**Comparison with Standards**:\n",
       "\n",
       "* The study uses a variety of software and databases, but the specific versions used are not mentioned.\n",
       "* The study could benefit from more detailed explanations of the algorithms and software used to ensure reproducibility.\n",
       "* The method section could benefit from more detailed step-by-step protocols to ensure that others can reproduce the results.\n",
       "\n",
       "**Recommendations**:\n",
       "\n",
       "* Provide more detailed explanations of the algorithms and software used, such as PocketMatch and Fpocket.\n",
       "* Mention the specific versions of software and databases used to ensure reproducibility.\n",
       "* Provide more detailed step-by-step protocols to ensure that others can reproduce the results.\n",
       "* Consider providing the Python scripts used in the study to ensure reproducibility.\n",
       "* Consider using more standardized software and databases to ensure reproducibility.\n",
       "##  **Appropriateness and Justification**\n",
       "**Overall Evaluation**: The study aims to find inhibitors for SARS CoV 2 proteins using a pocket similarity approach, but the method section and abstract could be improved for clarity and reproducibility.\n",
       "\n",
       "**Detailed Findings**:\n",
       "\n",
       "- **Relevance to Research Questions**: The study's research question is to find inhibitors for SARS CoV 2 proteins. The method section describes a process to calculate the similarity between approved drugs and SARS CoV 2 proteins, which is relevant to the research question. However, the abstract mentions finding drugs that inhibit the main protease, Nsp12, and Nsp3, but it is unclear how these specific proteins were targeted.\n",
       "\n",
       "- **Justifications Provided**: The method section provides some justifications for the use of PocketMatch and docking, but it would be helpful to provide more context on why these specific methods were chosen and how they relate to the research question. Additionally, the abstract mentions the significance of the study, but it is unclear what specific contribution the study makes to the field.\n",
       "\n",
       "- **Suitability of Methods**: The use of PocketMatch and docking is a suitable method for identifying potential inhibitors, but the study could benefit from more detail on the parameters used for docking and how the results were validated. The method section mentions the use of Fpocket to acquire pockets of all the pdbs, but it is unclear how the pockets were selected for analysis.\n",
       "\n",
       "- **Alternative Methods**: The study could have considered alternative methods for identifying potential inhibitors, such as molecular dynamics simulations or experimental validation. The abstract mentions that many in silico repurposing studies test binding of the compound to the target using docking, but it is unclear how the study's approach differs from these alternative methods.\n",
       "\n",
       "- **Validation of Novel Methods**: The study uses a novel approach by considering the dynamic behavior of the pocket after ligand binding, but it is unclear how this approach was validated. The method section mentions the use of python scripts to clean and process the pdbs, but it is unclear how these scripts were validated or tested.\n",
       "\n",
       "**Additional Comments**:\n",
       "\n",
       "* The study could benefit from more detail on the data preprocessing and cleaning steps, particularly with regards to the removal of small or non-specific compounds.\n",
       "* The use of python scripts to process the pdbs is a good approach, but it would be helpful to provide more information on how these scripts were designed and tested.\n",
       "* The study could benefit from more discussion on the limitations of the approach, particularly with regards to the potential for false positives or false negatives.\n",
       "* The abstract mentions the significance of the study, but it is unclear what specific contribution the study makes to the field.\n",
       "##  **Bias and Limitations**       \n",
       "**Overall Evaluation**: The study aims to repurpose approved drugs against COVID-19 using a pocket similarity approach. The method section provides a detailed description of the steps involved, but there are some concerns regarding control groups, variable handling, and potential biases.\n",
       "\n",
       "**Detailed Findings**:\n",
       "\n",
       "- **Control Groups**: The study lacks a clear description of control groups. It is unclear whether the study used a control group to compare the results with or if the results were compared to a baseline. The use of a control group would have helped to establish the significance of the findings. **Evaluation**: 2/5\n",
       "\n",
       "- **Variable Handling**: The study uses a complex pipeline involving multiple software tools (PocketMatch, Fpocket, and docking). However, the method section does not provide a clear description of how the variables were handled, such as how the distances between the center of mass of the pocket and the center of mass of the drug were calculated. This lack of clarity makes it difficult to reproduce the results. **Comments**: The study could benefit from a more detailed description of the variable handling process.\n",
       "\n",
       "- **Potential Biases**: The study uses a retrospective analysis of approved drugs, which may introduce biases. For example, the study may be biased towards drugs that have been previously studied or have a higher likelihood of being approved. Additionally, the study does not account for the dynamic behavior of the pocket after ligand binding, which may affect the accuracy of the results. **Identification**: The study may be susceptible to biases related to the retrospective analysis and the dynamic behavior of the pocket.\n",
       "\n",
       "- **Confounding Factors**: The study does not account for potential confounding factors, such as the presence of other proteins or ligands in the binding site, which may affect the accuracy of the results. **Identification**: The study may be susceptible to confounding factors related to the presence of other proteins or ligands in the binding site.\n",
       "\n",
       "- **Acknowledgment of Limitations**: The study acknowledges that many of the in silico repurposing studies test binding of the compound to the target using docking, but it does not discuss the limitations of this approach. **Observations**: The study could benefit from a more detailed discussion of the limitations of the approach.\n",
       "\n",
       "- **Mitigation Strategies**: The study does not provide any mitigation strategies to address the potential biases and confounding factors. **Assessment**: The study could benefit from the implementation of mitigation strategies to address the potential biases and confounding factors.\n",
       "\n",
       "Overall, the study provides a novel approach to repurposing approved drugs against COVID-19, but it lacks clarity in several areas, including control groups, variable handling, and potential biases. With some revisions to address these concerns, the study could provide more robust and reliable results."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import crq\n",
    "importlib.reload(crq)\n",
    "\n",
    "Markdown(crq.Critique(file_path, llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "IlckXLp5p-7c"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
